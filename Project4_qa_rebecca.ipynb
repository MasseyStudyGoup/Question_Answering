{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "rcParams['figure.dpi'] = 350\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "rcParams['figure.figsize'] = 15,10\n",
    "rcParams['font.size'] = 20\n",
    "rcParams['axes.labelsize'] = 'large'\n",
    "rcParams['xtick.labelsize'] = 20\n",
    "rcParams['ytick.labelsize'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "import nltk\n",
    "from nltk import clean_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "application = getDF('/data/QA/Appliances.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionType</th>\n",
       "      <th>asin</th>\n",
       "      <th>answerTime</th>\n",
       "      <th>unixTime</th>\n",
       "      <th>question</th>\n",
       "      <th>answerType</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Jun 27, 2014</td>\n",
       "      <td>1.403852e+09</td>\n",
       "      <td>I have a 9 year old Badger 1 that needs replac...</td>\n",
       "      <td>?</td>\n",
       "      <td>I replaced my old one with this without a hitch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open-ended</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Apr 28, 2014</td>\n",
       "      <td>1.398668e+09</td>\n",
       "      <td>model number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This may help InSinkErator Model BADGER-1: Bad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Aug 25, 2014</td>\n",
       "      <td>1.408950e+09</td>\n",
       "      <td>can I replace Badger 1 1/3 with a Badger 5 1/2...</td>\n",
       "      <td>?</td>\n",
       "      <td>Plumbing connections will vary with different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Nov 3, 2014</td>\n",
       "      <td>1.415002e+09</td>\n",
       "      <td>Does this come with power cord and dishwasher ...</td>\n",
       "      <td>?</td>\n",
       "      <td>It does not come with a power cord. It does co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open-ended</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Jun 21, 2014</td>\n",
       "      <td>1.403334e+09</td>\n",
       "      <td>loud noise inside when turned on. sounds like ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Check if you dropped something inside.Usually ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  questionType        asin    answerTime      unixTime  \\\n",
       "0       yes/no  B00004U9JP  Jun 27, 2014  1.403852e+09   \n",
       "1   open-ended  B00004U9JP  Apr 28, 2014  1.398668e+09   \n",
       "2       yes/no  B00004U9JP  Aug 25, 2014  1.408950e+09   \n",
       "3       yes/no  B00004U9JP   Nov 3, 2014  1.415002e+09   \n",
       "4   open-ended  B00004U9JP  Jun 21, 2014  1.403334e+09   \n",
       "\n",
       "                                            question answerType  \\\n",
       "0  I have a 9 year old Badger 1 that needs replac...          ?   \n",
       "1                                       model number        NaN   \n",
       "2  can I replace Badger 1 1/3 with a Badger 5 1/2...          ?   \n",
       "3  Does this come with power cord and dishwasher ...          ?   \n",
       "4  loud noise inside when turned on. sounds like ...        NaN   \n",
       "\n",
       "                                              answer  \n",
       "0   I replaced my old one with this without a hitch.  \n",
       "1  This may help InSinkErator Model BADGER-1: Bad...  \n",
       "2  Plumbing connections will vary with different ...  \n",
       "3  It does not come with a power cord. It does co...  \n",
       "4  Check if you dropped something inside.Usually ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "asin - ID of the product, e.g. B000050B6Z\n",
    "questionType - type of question. Could be 'yes/no' or 'open-ended'\n",
    "answerType - type of answer. Could be 'Y', 'N', or '?' (if the polarity of the answer could not be predicted). Only present for yes/no questions.\n",
    "answerTime - raw answer timestamp\n",
    "unixTime - answer timestamp converted to unix time\n",
    "question - question text\n",
    "answer - answer text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 TextBlob"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TextBlob Features:\n",
    "\n",
    "Noun phrase extraction\n",
    "Part-of-speech tagging\n",
    "Sentiment analysis\n",
    "Classification (Naive Bayes, Decision Tree)\n",
    "Language translation and detection powered by Google Translate\n",
    "Tokenization (splitting text into words and sentences)\n",
    "Word and phrase frequencies\n",
    "Parsing\n",
    "n-grams\n",
    "Word inflection (pluralization and singularization) and lemmatization\n",
    "Spelling correction\n",
    "Add new models or languages through extensions\n",
    "WordNet integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I have a 9 year old Badger 1 that needs replacing, will this Badger 1 install just like the original one?\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(application['question'][0])\n",
    "\n",
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['badger', 'badger'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases\n",
    "#??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I have a 9 year old Danger 1 that needs replacing, will this Danger 1 install just like the original one?\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.correct()\n",
    "# 改错了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer, PatternAnalyzer\n",
    "from textblob import Blobber\n",
    "tba = Blobber(analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='neg', p_pos=0.2430232741273017, p_neg=0.7569767258726988)\n"
     ]
    }
   ],
   "source": [
    "print tba(application['question'][0]).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"I have a 9 year old Badger 1 that needs replacing, will this Badger 1 install just like the original one?\")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"I have a 9 year old Badger 1 that needs replacing, will this Badger 1 install just like the original one?\")]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(application['question'][0], analyzer=PatternAnalyzer())\n",
    "blob.sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.2375, subjectivity=0.475)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Polarity ranges from -1 to 1 (1 = positive sentiment). \n",
    "#Subjectivity how much opinion is expressed within a given sentence: 0 = objective 1 = subjective\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Analyze the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 questionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'application' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-226-10f9ca7a60de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_application\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplication\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questionType'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'application' is not defined"
     ]
    }
   ],
   "source": [
    "q_application = application[['questionType','asin','question']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionType</th>\n",
       "      <th>asin</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>I have a 9 year old Badger 1 that needs replac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open-ended</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>model number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>can I replace Badger 1 1/3 with a Badger 5 1/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Does this come with power cord and dishwasher ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open-ended</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>loud noise inside when turned on. sounds like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  questionType        asin                                           question\n",
       "0       yes/no  B00004U9JP  I have a 9 year old Badger 1 that needs replac...\n",
       "1   open-ended  B00004U9JP                                       model number\n",
       "2       yes/no  B00004U9JP  can I replace Badger 1 1/3 with a Badger 5 1/2...\n",
       "3       yes/no  B00004U9JP  Does this come with power cord and dishwasher ...\n",
       "4   open-ended  B00004U9JP  loud noise inside when turned on. sounds like ..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_application.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mapping = {\"yes/no\": 1, \"open-ended\": 0}\n",
    "q_application['questionType'] = q_application['questionType'].replace(mapping).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionType</th>\n",
       "      <th>asin</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>I have a 9 year old Badger 1 that needs replac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>model number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>can I replace Badger 1 1/3 with a Badger 5 1/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Does this come with power cord and dishwasher ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>loud noise inside when turned on. sounds like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   questionType        asin                                           question\n",
       "0             1  B00004U9JP  I have a 9 year old Badger 1 that needs replac...\n",
       "1             0  B00004U9JP                                       model number\n",
       "2             1  B00004U9JP  can I replace Badger 1 1/3 with a Badger 5 1/2...\n",
       "3             1  B00004U9JP  Does this come with power cord and dishwasher ...\n",
       "4             0  B00004U9JP  loud noise inside when turned on. sounds like ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_application.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train queationType classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9011,)\n",
      "(9011,)\n"
     ]
    }
   ],
   "source": [
    "X_train = q_application.question.values\n",
    "y_train = q_application.questionType.values\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  7582\n",
      "Accuracy:  0.7585441633377719\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(q_application.question.values, q_application.questionType.values, random_state=1, train_size=0.75)\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "print 'Features: ', train_dtm.shape[1]\n",
    "test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)\n",
    "y_pred_class = nb.predict(test_dtm)\n",
    "print 'Accuracy: ', metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6758, 7582)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "print train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "train_tfidf = transformer.fit_transform(train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/QA/count_vect']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the training model & vector\n",
    "joblib.dump(nb, '/data/QA/model.pkl')\n",
    "joblib.dump(vect, '/data/QA/count_vect')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test other ways of normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spit_into_lemmas(text):\n",
    "    text = unicode(text, 'utf-8').lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  7509\n",
      "Accuracy:  0.7612072791833111\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=spit_into_lemmas)\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "print 'Features: ', train_dtm.shape[1]\n",
    "test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)\n",
    "y_pred_class = nb.predict(test_dtm)\n",
    "print 'Accuracy: ', metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do a new prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('/data/QA/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = joblib.load('/data/QA/count_vect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(q_application.question.values, q_application.questionType.values, random_state=1, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_data = [q_application['question'][0]]\n",
    "#testing_data = ['loud noise inside when turned on. sounds like']\n",
    "#testing_data = ['can I replace Badger 1 1/3 with a Badger?']\n",
    "testing_data = ['can I ask a question?']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_counts = count_vect.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_tfidf = tfidf_transformer.fit_transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(X_new_tfidf)\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train question-answer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionType</th>\n",
       "      <th>asin</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>I have a 9 year old Badger 1 that needs replac...</td>\n",
       "      <td>I replaced my old one with this without a hitch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open-ended</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>model number</td>\n",
       "      <td>This may help InSinkErator Model BADGER-1: Bad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>can I replace Badger 1 1/3 with a Badger 5 1/2...</td>\n",
       "      <td>Plumbing connections will vary with different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes/no</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Does this come with power cord and dishwasher ...</td>\n",
       "      <td>It does not come with a power cord. It does co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open-ended</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>loud noise inside when turned on. sounds like ...</td>\n",
       "      <td>Check if you dropped something inside.Usually ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  questionType        asin                                           question  \\\n",
       "0       yes/no  B00004U9JP  I have a 9 year old Badger 1 that needs replac...   \n",
       "1   open-ended  B00004U9JP                                       model number   \n",
       "2       yes/no  B00004U9JP  can I replace Badger 1 1/3 with a Badger 5 1/2...   \n",
       "3       yes/no  B00004U9JP  Does this come with power cord and dishwasher ...   \n",
       "4   open-ended  B00004U9JP  loud noise inside when turned on. sounds like ...   \n",
       "\n",
       "                                              answer  \n",
       "0   I replaced my old one with this without a hitch.  \n",
       "1  This may help InSinkErator Model BADGER-1: Bad...  \n",
       "2  Plumbing connections will vary with different ...  \n",
       "3  It does not come with a power cord. It does co...  \n",
       "4  Check if you dropped something inside.Usually ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a = application[['questionType','asin','question','answer']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionType</th>\n",
       "      <th>asin</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>I have a 9 year old Badger 1 that needs replac...</td>\n",
       "      <td>I replaced my old one with this without a hitch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>model number</td>\n",
       "      <td>This may help InSinkErator Model BADGER-1: Bad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>can I replace Badger 1 1/3 with a Badger 5 1/2...</td>\n",
       "      <td>Plumbing connections will vary with different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>Does this come with power cord and dishwasher ...</td>\n",
       "      <td>It does not come with a power cord. It does co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>B00004U9JP</td>\n",
       "      <td>loud noise inside when turned on. sounds like ...</td>\n",
       "      <td>Check if you dropped something inside.Usually ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   questionType        asin  \\\n",
       "0             1  B00004U9JP   \n",
       "1             0  B00004U9JP   \n",
       "2             1  B00004U9JP   \n",
       "3             1  B00004U9JP   \n",
       "4             0  B00004U9JP   \n",
       "\n",
       "                                            question  \\\n",
       "0  I have a 9 year old Badger 1 that needs replac...   \n",
       "1                                       model number   \n",
       "2  can I replace Badger 1 1/3 with a Badger 5 1/2...   \n",
       "3  Does this come with power cord and dishwasher ...   \n",
       "4  loud noise inside when turned on. sounds like ...   \n",
       "\n",
       "                                              answer  \n",
       "0   I replaced my old one with this without a hitch.  \n",
       "1  This may help InSinkErator Model BADGER-1: Bad...  \n",
       "2  Plumbing connections will vary with different ...  \n",
       "3  It does not come with a power cord. It does co...  \n",
       "4  Check if you dropped something inside.Usually ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\"yes/no\": 1, \"open-ended\": 0}\n",
    "q_a['questionType'] = q_a['questionType'].replace(mapping).astype(np.int)\n",
    "q_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9011,)\n",
      "(9011,)\n"
     ]
    }
   ],
   "source": [
    "X_train = q_a.question.values\n",
    "y_train = q_a.answer.values\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  10000\n",
      "Accuracy:  0.029738126941855306\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2),stop_words='english', max_features=10000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(q_a.question.values, q_a.answer.values, random_state=1, train_size=0.75)\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "print 'Features: ', train_dtm.shape[1]\n",
    "test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)\n",
    "y_pred_class = nb.predict(test_dtm)\n",
    "print 'Accuracy: ', metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 question similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = raw_input(\"Hi, how can I help you?\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how to use the washer?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = q_application.question.values\n",
    "data=np.append(data,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_closest(target, k, distance_matrix, data):\n",
    "   \n",
    "    res = list(np.argsort(distance_matrix[target])[-k-1:-1])\n",
    "    res.reverse()   \n",
    "    result = [ (S[target,i], data[i]) for i in res]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4531438669924055, 'how loud is this washer?'),\n",
       " (0.4530932875169346, 'how to remove front of washer to get to pump'),\n",
       " (0.44047534165057606, 'how much detergent do I use in the Danby 1.7 washer?'),\n",
       " (0.3896558331924539, 'How do you use the disposal')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 4\n",
    "target = len(data)-1\n",
    "question = select_k_closest(target, k, S, data)\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnswer(question):    ##question is the result of select_k_closest\n",
    "    answer_set = []\n",
    "    for i in range(len(question)):\n",
    "        answer_set.append(application[application['question']==question[i][1]])\n",
    "    return answer_set[0]['answer']   ##return the first answer\n",
    "#    return answer_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7935    compared to maytag I can barely tell the dishe...\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAnswer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/93/0978a08e622dda7620570450529b8e27ff5fbac41e55747e61f3e420e143/gensim-3.6.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.0MB 505kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /anaconda2/lib/python2.7/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /anaconda2/lib/python2.7/site-packages (from gensim) (1.14.3)\n",
      "Collecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
      "Requirement already satisfied: six>=1.5.0 in /anaconda2/lib/python2.7/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: boto>=2.32 in /anaconda2/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim) (2.48.0)\n",
      "Collecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /anaconda2/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/06/b9e2f15abbffa4103c6b2bdaab89d6753240c4c1b25e20b6866a29d7fd26/boto3-1.9.20-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 229kB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda2/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /anaconda2/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda2/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda2/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
      "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 556kB/s \n",
      "\u001b[?25hCollecting botocore<1.13.0,>=1.12.20 (from boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/36/7f98f2c60f18cff95764b55436cd62633d51bc3180b5d398755196960ff9/botocore-1.12.20-py2.py3-none-any.whl (4.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.7MB 1.3MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: futures<4.0.0,>=2.2.0; python_version == \"2.6\" or python_version == \"2.7\" in /anaconda2/lib/python2.7/site-packages (from s3transfer<0.2.0,>=0.1.10->boto3->smart-open>=1.2.1->gensim) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda2/lib/python2.7/site-packages (from botocore<1.13.0,>=1.12.20->boto3->smart-open>=1.2.1->gensim) (2.7.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda2/lib/python2.7/site-packages (from botocore<1.13.0,>=1.12.20->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
      "Building wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/liunan/Library/Caches/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/liunan/Library/Caches/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: bz2file, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.9.20 botocore-1.12.20 bz2file-0.98 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english') + [\n",
    "    '.',\n",
    "    ',',\n",
    "    '--',\n",
    "    '\\'s',\n",
    "    '?',\n",
    "    ')',\n",
    "    '(',\n",
    "    ':',\n",
    "    '\\'',\n",
    "    '\\'re',\n",
    "    '\"',\n",
    "    '-',\n",
    "    '}',\n",
    "    '{',\n",
    "    u'—',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英文预处理\n",
    "\n",
    "https://blog.csdn.net/caicai1617/article/details/21690911"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorize with answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "#w means tokens are made of only alphanumeric characters where + indicates that they comprise of one or more of such characters\n",
    "tokenizer = RegexpTokenizer('\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete number and symbol\n",
    "import string\n",
    "def CleanLines(text):\n",
    "    cleanLine = []\n",
    "    identify = string.maketrans('', '')\n",
    "    delEStr = string.punctuation +string.digits\n",
    "    \n",
    "    for i in text:       \n",
    "        lines = i.translate(identify,delEStr)\n",
    "        cleanLine.append(lines) \n",
    "    return cleanLine\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_answer = CleanLines(application['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add token in answer question\n",
    "def getToken(text):\n",
    "    token_as = []\n",
    "    for i in text:\n",
    "        tokens = tokenizer.tokenize(i)\n",
    "        token_as.append(tokens)\n",
    "    #return token_as\n",
    "    return token_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_answer = getToken(t_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete stop words and make lowercase ?? not lower\n",
    "def cleanword(text):\n",
    "    stop_w = []\n",
    "    for e in text:\n",
    "        content = [w.lower() for w in e if w.lower() not in stopwords]\n",
    "        stop_w.append(content)\n",
    "    return stop_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_answer = cleanword(t_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/zl_best/article/details/53433072\n",
    "\n",
    "Word2Vec参数说明：https://blog.csdn.net/szlcw1/article/details/52751314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(t_answer, sg=1, size=100,  window=5,  min_count=5,  negative=3, sample=0.001, hs=1, workers=5)\n",
    "model.save('/data/QA/application_a.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('/data/QA/application_a.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02150281, -0.00266735, -0.13015597,  0.07824621, -0.06933703,\n",
       "       -0.08956843,  0.00779961, -0.12313762,  0.14651246, -0.00365247,\n",
       "       -0.12158015, -0.06919064, -0.03216884,  0.01797071, -0.00170094,\n",
       "        0.0574705 , -0.12896118, -0.01069618,  0.04712673, -0.25119805,\n",
       "       -0.15948378, -0.00061552,  0.10650717,  0.09076841, -0.09648447,\n",
       "       -0.08760342, -0.0484775 , -0.07376955, -0.05841612, -0.0598413 ,\n",
       "       -0.08822629,  0.07127231, -0.07263125, -0.05387486, -0.06742014,\n",
       "        0.13302256, -0.15907906,  0.00161945,  0.05186029,  0.01987283,\n",
       "       -0.03993224,  0.00598737, -0.10475038,  0.12639731,  0.09150562,\n",
       "       -0.19552936,  0.08593322,  0.06026267,  0.04370295,  0.13887832,\n",
       "       -0.01136994, -0.05982323, -0.152624  ,  0.00375134, -0.08138216,\n",
       "        0.01066376, -0.05831333, -0.1850282 , -0.0952899 ,  0.03068771,\n",
       "       -0.09719677,  0.02842921,  0.07285914,  0.0468903 ,  0.03119747,\n",
       "       -0.09669027,  0.09115966,  0.06533805,  0.1598633 ,  0.01474923,\n",
       "       -0.07014643, -0.04797783, -0.12361582,  0.09912796, -0.14894754,\n",
       "       -0.00545279,  0.03001841, -0.02765356,  0.22702096,  0.18146557,\n",
       "       -0.02830527,  0.16418421, -0.1045656 , -0.14087857,  0.02532307,\n",
       "       -0.02596748, -0.12275267, -0.15459229,  0.20529692,  0.06703693,\n",
       "       -0.11897748, -0.1224705 , -0.16333854, -0.00939212, -0.08266503,\n",
       "       -0.02906337, -0.02753844,  0.11341096, -0.24420434, -0.08844643],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['computer'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda2/lib/python2.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('patio', 0.8586839437484741),\n",
       " ('rv', 0.8438653349876404),\n",
       " ('switched', 0.8431739807128906),\n",
       " ('sat', 0.8376901149749756),\n",
       " ('stud', 0.8371859788894653),\n",
       " ('Love', 0.8371580839157104),\n",
       " ('expecting', 0.834181547164917),\n",
       " ('eyes', 0.8295118808746338),\n",
       " ('initially', 0.8266298770904541),\n",
       " ('meat', 0.8266057372093201)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('computer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorize questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_question = CleanLines(application['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_question = getToken(t_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_question = addstopword(t_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(t_question, sg=1, size=100,  window=5,  min_count=5,  negative=3, sample=0.001, hs=1, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/data/QA/application_q.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相似度应用\n",
    "https://blog.csdn.net/u014595019/article/details/52218249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflearn in /anaconda2/lib/python2.7/site-packages (0.3.2)\n",
      "Requirement already satisfied: Pillow in /anaconda2/lib/python2.7/site-packages (from tflearn) (5.1.0)\n",
      "Requirement already satisfied: six in /anaconda2/lib/python2.7/site-packages (from tflearn) (1.11.0)\n",
      "Requirement already satisfied: numpy in /anaconda2/lib/python2.7/site-packages (from tflearn) (1.14.3)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: tensorflow in /anaconda2/lib/python2.7/site-packages (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools<=39.1.0 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: enum34>=1.1.6 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.1.6)\n",
      "Requirement already satisfied, skipping upgrade: backports.weakref>=1.0rc1 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.0.post1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.5 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.0.6)\n",
      "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.3 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /anaconda2/lib/python2.7/site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.12.0,>=1.11.0 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.14.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (3.6.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /anaconda2/lib/python2.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /anaconda2/lib/python2.7/site-packages (from keras-applications>=1.0.5->tensorflow) (2.7.1)\n",
      "Requirement already satisfied, skipping upgrade: funcsigs>=1; python_version < \"3.3\" in /anaconda2/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: pbr>=0.11 in /anaconda2/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /anaconda2/lib/python2.7/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: futures>=3.1.1; python_version < \"3\" in /anaconda2/lib/python2.7/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /anaconda2/lib/python2.7/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (0.14.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: protobuf in /anaconda2/lib/python2.7/site-packages (3.6.1)\n",
      "Requirement already satisfied: setuptools in /anaconda2/lib/python2.7/site-packages (from protobuf) (39.1.0)\n",
      "Requirement already satisfied: six>=1.9 in /anaconda2/lib/python2.7/site-packages (from protobuf) (1.11.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2Vec' object has no attribute 'max_seq_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-65bd6e460dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"XY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Word2Vec' object has no attribute 'max_seq_len'"
     ]
    }
   ],
   "source": [
    "input_data = tflearn.input_data(shape=[None, model.max_seq_len*2, self.word_vec_dim], dtype=tf.float32, name = \"XY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nIn = 100\n",
    "nHidden = 25\n",
    "nOut = 200\n",
    "alpha = 0.2\n",
    "\n",
    "batchSize = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tflearn.input_data(shape=[None,nIn])\n",
    "layer2 = tflearn.fully_connected(input_layer, nHidden, activation = 'sigmoid')\n",
    "out = tflearn.fully_connected(layer2, nOut, activation = 'softmax')\n",
    "\n",
    "network = tflearn.regression(out, optimizer='adam', loss='categorical_crossentropy', learning_rate = alpha, batch_size=batchSize)\n",
    "\n",
    "model = tflearn.RNN(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, n_epoch=nEpochs, show_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Accuracy:\", model.evaluate(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# things we need for NLP\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our intents file\n",
    "import json\n",
    "\n",
    "def getdata(path):\n",
    "    g = open(path,'r')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "\n",
    "intents = list(getdata('/data/QA/QA_Video_Games.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english') + [\n",
    "    '.',\n",
    "    ',',\n",
    "    '--',\n",
    "    '\\'s',\n",
    "    '?',\n",
    "    ')',\n",
    "    '(',\n",
    "    ':',\n",
    "    '\\'',\n",
    "    '\\'re',\n",
    "    '\"',\n",
    "    '-',\n",
    "    '}',\n",
    "    '{',\n",
    "    u'—',\n",
    "    '',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "def CleanLines(text):\n",
    "    cleanLine = []\n",
    "    identify = string.maketrans('', '')\n",
    "    delEStr = string.punctuation +string.digits\n",
    "    for i in text:         \n",
    "        i = i.encode(\"utf-8\")\n",
    "        lines = i.translate(identify,delEStr)\n",
    "        cleanLine.append(lines) \n",
    "    return cleanLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni(text):\n",
    "    uni_text = []\n",
    "    for i in text:\n",
    "        i = unicode(i, \"utf-8\")\n",
    "        uni_text.append(i)\n",
    "    return uni_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deuni(text):\n",
    "    deuni_text = []\n",
    "    for i in text:\n",
    "        i = i.encode(\"utf-8\")\n",
    "        deuni_text.append(i)\n",
    "    return deuni_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete long words\n",
    "def long_word_filter(words):\n",
    "    word_list = []\n",
    "    for i in words:\n",
    "        if len(i)<15:\n",
    "            word_list.append(i)\n",
    "        \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7744, 'documents')\n",
      "(1183, 'classes')\n",
      "(13772, 'unique stemmed words')\n",
      "(28893, 'answers')\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "answers = []\n",
    "\n",
    "# loop through each question in our intents\n",
    "for intent in intents:\n",
    "    for question in intent['questions']:\n",
    "        # tokenize each word in the sentence\n",
    "        #text = CleanLines(question['questionText'])\n",
    "        w = nltk.word_tokenize(question['questionText'])\n",
    "        w = CleanLines(w)\n",
    "        w = uni(w)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        documents.append((w, intent['asin']))\n",
    "        # add to our classes list\n",
    "        if intent['asin'] not in classes:\n",
    "            classes.append(intent['asin'])\n",
    "        \n",
    "        for answer in question['answers']:\n",
    "            w2 = nltk.word_tokenize(answer['answerText'])\n",
    "            w2 = CleanLines(w2)\n",
    "            w2 = uni(w2)\n",
    "            words.extend(w2)\n",
    "            answers.append((w,w2))\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in stop_words]\n",
    "words = sorted(list(set(words)))\n",
    "words = deuni(words)\n",
    "words = long_word_filter(words)\n",
    "\n",
    "# remove duplicates\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\")\n",
    "print (len(words), \"unique stemmed words\")\n",
    "print (len(answers), \"answers\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:19: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "output = []\n",
    "\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    question_words = doc[0]\n",
    "    # stem each word\n",
    "    question_words = [stemmer.stem(word.lower()) for word in question_words]\n",
    "    \n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in question_words else bag.append(0)\n",
    "    \n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7744"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-cdb1957f1062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/base_any2vec.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/base_any2vec.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/base_any2vec.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/base_any2vec.pyc\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/gensim/models/base_any2vec.pyc\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/Queue.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Word2Vec(words, sg=1, size=100,  window=5,  min_count=5,  negative=3, sample=0.001, hs=1, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/data/QA/Game.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec.load('/data/QA/Game.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import rnn\n",
    "import chardet\n",
    "import numpy as np\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_seqs = []\n",
    "answer_seqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_w = 50\n",
    "float_size = 4\n",
    "word_vector_dict = {}\n",
    "word_vec_dim = 100\n",
    "max_seq_len = 8\n",
    "word_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open('/data/QA/Game.bin', \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x80'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_and_size = input_file.readline()\n",
    "words_and_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x80\\x02cgensim.models.word2vec'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_and_size.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for long() with base 10: '\\x80\\x02cgensim.models.word2vec\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b7c3606ff812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_and_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for long() with base 10: '\\x80\\x02cgensim.models.word2vec\\n'"
     ]
    }
   ],
   "source": [
    "words = long(words_and_size.split(' ')[0])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0277258 , -0.15726964,  0.23922774, -0.01904267, -0.10565194,\n",
       "        0.07390157,  0.04503018,  0.01647286,  0.28594834,  0.2821932 ,\n",
       "       -0.1446266 , -0.02573078, -0.13981101, -0.00779268,  0.00611291,\n",
       "        0.24701291,  0.04923122,  0.11865059,  0.01996559,  0.05199368,\n",
       "        0.10256855,  0.12916183,  0.08025157,  0.06846515, -0.13114893,\n",
       "        0.015908  ,  0.1035057 ,  0.04631276, -0.03442198,  0.15926026,\n",
       "       -0.13928509, -0.13234141,  0.07017811,  0.09472259, -0.20627746,\n",
       "       -0.00197215, -0.06064624, -0.03610892,  0.20154928,  0.08365507,\n",
       "       -0.04813718, -0.06157881, -0.09222899,  0.1056164 , -0.0089402 ,\n",
       "       -0.08241719, -0.10129223,  0.10501397, -0.13239072, -0.00579549,\n",
       "       -0.11169685, -0.16966498, -0.04024898, -0.07752605,  0.03528985,\n",
       "       -0.07535794,  0.18826069, -0.04408138, -0.05332544, -0.07716881,\n",
       "       -0.00373244, -0.03787516, -0.07968268, -0.16284847, -0.03662417,\n",
       "       -0.08013629, -0.03653821,  0.08343095,  0.07536754, -0.02534193,\n",
       "       -0.10197284,  0.06565011, -0.01649449, -0.00363975, -0.02166289,\n",
       "        0.15413313,  0.06498487,  0.1122127 , -0.08952831, -0.05615366,\n",
       "       -0.16736753,  0.05967089,  0.08024918, -0.11679676, -0.03718988,\n",
       "        0.04711454, -0.10950822,  0.03598069,  0.04501143,  0.15853982,\n",
       "       -0.09850161, -0.00756954,  0.04765397,  0.1058271 , -0.2102316 ,\n",
       "       -0.07616503,  0.03694746,  0.08874313, -0.09476611, -0.11752665],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write question answer pair & Word2Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding( \"utf-8\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"/data/QA/QA_pair.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for i in range(len(answers)):\n",
    "    question = deuni(answers[i][0])\n",
    "    questions.append(question) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers1 =[]\n",
    "for i in range(len(answers)):\n",
    "    answer = deuni(answers[i][1])\n",
    "    answers1.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for vectorize\n",
    "words = []\n",
    "for i in range(len(answers)):\n",
    "    question = deuni(answers[i][0])\n",
    "    answer = deuni(answers[i][1])\n",
    "    words.append(question)\n",
    "    words.append(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vector\n",
    "model = Word2Vec(words, sg=1, size=100,  window=5,  min_count=5,  negative=3, sample=0.001, hs=1, workers=5)\n",
    "model.save('/data/QA/Game_words.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(questions)):\n",
    "    for w_q in questions[i]:\n",
    "        w_q = w_q.lower()\n",
    "        fo.write( w_q+' ')\n",
    "        \n",
    "    fo.write('|')\n",
    "    \n",
    "    for w_a in answers1[i]:\n",
    "        w_a = w_a.lower()\n",
    "        fo.write(w_a+' ')\n",
    "    \n",
    "    fo.write('\\n')\n",
    "            \n",
    "fo.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28893\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"/data/QA/QA_pair.txt\", \"r\")\n",
    "print  len(fo.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c80f45e55979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_w2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_w2v' is not defined"
     ]
    }
   ],
   "source": [
    "type(model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__hash__',\n",
       " '__ignoreds',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__numpys',\n",
       " '__recursive_saveloads',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__scipys',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_check_input_data_sanity',\n",
       " '_check_training_sanity',\n",
       " '_clear_post_train',\n",
       " '_do_train_epoch',\n",
       " '_do_train_job',\n",
       " '_get_job_params',\n",
       " '_get_thread_working_mem',\n",
       " '_job_producer',\n",
       " '_load_specials',\n",
       " '_log_epoch_end',\n",
       " '_log_epoch_progress',\n",
       " '_log_progress',\n",
       " '_log_train_end',\n",
       " '_minimize_model',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_set_train_params',\n",
       " '_smart_save',\n",
       " '_train_epoch',\n",
       " '_train_epoch_corpusfile',\n",
       " '_update_job_params',\n",
       " '_worker_loop',\n",
       " '_worker_loop_corpusfile',\n",
       " 'accuracy',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'build_vocab_from_freq',\n",
       " 'callbacks',\n",
       " 'cbow_mean',\n",
       " 'clear_sims',\n",
       " 'compute_loss',\n",
       " 'corpus_count',\n",
       " 'corpus_total_words',\n",
       " 'cum_table',\n",
       " 'delete_temporary_training_data',\n",
       " 'doesnt_match',\n",
       " 'epochs',\n",
       " 'estimate_memory',\n",
       " 'evaluate_word_pairs',\n",
       " 'get_latest_training_loss',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'init_sims',\n",
       " 'intersect_word2vec_format',\n",
       " 'iter',\n",
       " 'layer1_size',\n",
       " 'load',\n",
       " 'load_word2vec_format',\n",
       " 'log_accuracy',\n",
       " 'max_final_vocab',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'model_trimmed_post_training',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'n_similarity',\n",
       " 'negative',\n",
       " 'ns_exponent',\n",
       " 'predict_output_word',\n",
       " 'random',\n",
       " 'reset_from',\n",
       " 'running_training_loss',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'save_word2vec_format',\n",
       " 'score',\n",
       " 'sg',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'syn0_lockf',\n",
       " 'syn1',\n",
       " 'syn1neg',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'trainables',\n",
       " 'vector_size',\n",
       " 'vocabulary',\n",
       " 'window',\n",
       " 'wmdistance',\n",
       " 'workers',\n",
       " 'wv']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vector\n",
    "model_w2v = Word2Vec.load('/data/QA/Game_words.bin')\n",
    "word_vector=model_w2v.wv\n",
    "#word_vocab = model_w2v.vocabulary\n",
    "word_vector_dict = word_vector.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector_dict.has_key('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01847144,  0.2502406 ,  0.15627031,  0.09494841,  0.23786339,\n",
       "       -0.05098917,  0.03672797,  0.10033745, -0.12306379,  0.40702227,\n",
       "        0.06122517,  0.1543013 , -0.08173149, -0.5054856 , -0.30113924,\n",
       "       -0.33783647,  0.47734186, -0.17596556,  0.00078394, -0.14734691,\n",
       "        0.19012609,  0.14645573, -0.04547663, -0.20754956, -0.08232286,\n",
       "        0.33851036,  0.2276305 , -0.15445256, -0.6604043 , -0.10005897,\n",
       "       -0.35435748, -0.31129393,  0.33122015,  0.04844597, -0.31885263,\n",
       "        0.46004468, -0.3187674 ,  0.14773747, -0.30041856, -0.10771601,\n",
       "        0.02037544, -0.05955373, -0.01610406, -0.42252117, -0.45313025,\n",
       "       -0.34191176, -0.33028093, -0.08195064, -0.27875954, -0.31928095,\n",
       "       -0.07102174,  0.22368523,  0.06321266,  0.07697222,  0.29968724,\n",
       "        0.21402255,  0.2636317 ,  0.14932515, -0.25810167, -0.06156397,\n",
       "        0.02456847,  0.42668632,  0.28095636,  0.08311479,  0.00606459,\n",
       "        0.52734405,  0.4133043 , -0.021176  ,  0.52952296, -0.3744854 ,\n",
       "        0.22640194,  0.7375096 , -0.7697332 ,  0.22034389, -0.38763735,\n",
       "       -0.38566688,  0.3837321 ,  0.34978896, -0.23838642, -0.29791278,\n",
       "       -0.39880034,  0.33733287, -0.11768834,  0.02855572, -0.21039571,\n",
       "       -0.0379485 ,  0.10513801, -0.27419487,  0.10231505,  0.38011983,\n",
       "        0.3155879 , -0.04232009,  0.41426823, -0.16153467, -0.06900783,\n",
       "       -0.09558885, -0.04625923,  0.33912602,  0.17441557,  0.16238093],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seq(input_file):\n",
    "    \"\"\"读取切好词的文本文件，加载全部词序列\n",
    "    \"\"\"\n",
    "    file_object = open(input_file, 'r')\n",
    "    vocab_dict = {}\n",
    "    while True:\n",
    "        question_seq = []\n",
    "        answer_seq = []\n",
    "        line = file_object.readline()\n",
    "        if line:\n",
    "            line_pair = line.split('|')\n",
    "            line_question = line_pair[0]\n",
    "            line_answer = line_pair[1]\n",
    "            for word in line_question.split(' '):\n",
    "                if word_vector_dict.has_key(word):\n",
    "                    question_seq.append(word_vector[word])\n",
    "            for word in line_answer.decode('utf-8').split(' '):\n",
    "                if word_vector_dict.has_key(word):\n",
    "                    answer_seq.append(word_vector[word])\n",
    "        else:\n",
    "            break\n",
    "        question_seqs.append(question_seq)\n",
    "        answer_seqs.append(answer_seq)\n",
    "    file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import rnn\n",
    "import chardet\n",
    "import numpy as np\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vectorized question & answer \n",
    "question_seqs=[]\n",
    "answer_seqs=[]\n",
    "init_seq('/data/QA/QA_pair.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_seq_len(seqs):\n",
    "    seq_lens = []\n",
    "    for seq in seqs:\n",
    "        seq_lens.append(len(seq))\n",
    "        seq_lens.sort(reverse=True)\n",
    "    return seq_lens[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556 1928\n"
     ]
    }
   ],
   "source": [
    "max_q_seq = get_max_seq_len(question_seqs)\n",
    "max_a_seq = get_max_seq_len(answer_seqs)\n",
    "print max_q_seq,max_a_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2484"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max_q_seq + max_a_seq\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySeq2Seq(object):\n",
    "    def __init__(self, max_seq_len = 164, word_vec_dim = 100, input_file='/data/QA/QA_pair.txt'):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.word_vec_dim = word_vec_dim\n",
    "        self.input_file = input_file\n",
    "    \n",
    "    def generate_trainig_data(self):\n",
    " #       load_word_set()\n",
    " #       load_vectors(\"/data/QA/Game_words.bin\")\n",
    "        init_seq(self.input_file)\n",
    "        xy_data = []\n",
    "        y_data = []\n",
    "        for i in range(len(question_seqs)):\n",
    "        #for i in range(100):\n",
    "            question_seq = question_seqs[i]\n",
    "            answer_seq = answer_seqs[i]\n",
    "            if len(question_seq) < self.max_seq_len and len(answer_seq) < self.max_seq_len:\n",
    "                #多余的位设为0，与question的reverse合并，为什么要reverse？ * - repeat ；+ - 合并\n",
    "                sequence_ry = [np.zeros(self.word_vec_dim)] * (self.max_seq_len-len(question_seq)) + list(reversed(question_seq))\n",
    "                #多余的位设为0， 与answer合并\n",
    "                sequence_y = answer_seq + [np.zeros(self.word_vec_dim)] * (self.max_seq_len-len(answer_seq))\n",
    "                #合并\n",
    "                sequence_xy = sequence_ry + sequence_y\n",
    "                sequence_y = [np.ones(self.word_vec_dim)] + sequence_y\n",
    "                xy_data.append(sequence_xy)\n",
    "                y_data.append(sequence_y)\n",
    "\n",
    "                #print \"right answer\"\n",
    "                #for w in answer_seq:\n",
    "                #    (match_word, max_cos) = vector2word(w)\n",
    "                #    if len(match_word)>0:\n",
    "                #        print match_word, vector_sqrtlen(w)\n",
    "\n",
    "        return np.array(xy_data), np.array(y_data)\n",
    "    \n",
    "    \n",
    "    def model(self, feed_previous=False):\n",
    "        # 通过输入的XY生成encoder_inputs和带GO头的decoder_inputs\n",
    "        input_data = tflearn.input_data(shape=[None, self.max_seq_len*2, self.word_vec_dim], dtype=tf.float32, name = \"XY\")\n",
    "        encoder_inputs = tf.slice(input_data, [0, 0, 0], [-1, self.max_seq_len, self.word_vec_dim], name=\"enc_in\")\n",
    "        decoder_inputs_tmp = tf.slice(input_data, [0, self.max_seq_len, 0], [-1, self.max_seq_len-1, self.word_vec_dim], name=\"dec_in_tmp\")\n",
    "        go_inputs = tf.ones_like(decoder_inputs_tmp)\n",
    "        go_inputs = tf.slice(go_inputs, [0, 0, 0], [-1, 1, self.word_vec_dim])\n",
    "        decoder_inputs = tf.concat(1, [go_inputs, decoder_inputs_tmp], name=\"dec_in\")\n",
    "\n",
    "        # 编码器\n",
    "        # 把encoder_inputs交给编码器，返回一个输出(预测序列的第一个值)和一个状态(传给解码器)\n",
    "        (encoder_output_tensor, states) = tflearn.lstm(encoder_inputs, self.word_vec_dim, return_state=True, scope='encoder_lstm')\n",
    "        encoder_output_sequence = tf.pack([encoder_output_tensor], axis=1)\n",
    "\n",
    "        # 解码器\n",
    "        # 预测过程用前一个时间序的输出作为下一个时间序的输入\n",
    "        # 先用编码器的最后一个输出作为第一个输入\n",
    "        if feed_previous:\n",
    "            first_dec_input = go_inputs\n",
    "        else:\n",
    "            first_dec_input = tf.slice(decoder_inputs, [0, 0, 0], [-1, 1, self.word_vec_dim])\n",
    "        decoder_output_tensor = tflearn.lstm(first_dec_input, self.word_vec_dim, initial_state=states, return_seq=False, reuse=False, scope='decoder_lstm')\n",
    "        decoder_output_sequence_single = tf.pack([decoder_output_tensor], axis=1)\n",
    "        decoder_output_sequence_list = [decoder_output_tensor]\n",
    "        # 再用解码器的输出作为下一个时序的输入\n",
    "        for i in range(self.max_seq_len-1):\n",
    "            if feed_previous:\n",
    "                next_dec_input = decoder_output_sequence_single\n",
    "            else:\n",
    "                next_dec_input = tf.slice(decoder_inputs, [0, i+1, 0], [-1, 1, self.word_vec_dim])\n",
    "            decoder_output_tensor = tflearn.lstm(next_dec_input, self.word_vec_dim, return_seq=False, reuse=True, scope='decoder_lstm')\n",
    "            decoder_output_sequence_single = tf.pack([decoder_output_tensor], axis=1)\n",
    "            decoder_output_sequence_list.append(decoder_output_tensor)\n",
    "\n",
    "        decoder_output_sequence = tf.pack(decoder_output_sequence_list, axis=1)\n",
    "        real_output_sequence = tf.concat(1, [encoder_output_sequence, decoder_output_sequence])\n",
    "\n",
    "        net = tflearn.regression(real_output_sequence, optimizer='sgd', learning_rate=0.1, loss='mean_square')\n",
    "        model = tflearn.DNN(net)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        trainXY, trainY = self.generate_trainig_data()\n",
    "        model = self.model(feed_previous=False)\n",
    "        model.fit(trainXY, trainY, n_epoch=1000, snapshot_epoch=False, batch_size=1)\n",
    "        model.save('/data/QA/model_tensorflow')\n",
    "        return model\n",
    "    \n",
    "    def load(self):\n",
    "        model = self.model(feed_previous=True)\n",
    "        model.load('/data/QA/model_tensorflow')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = MySeq2Seq( max_seq_len = 164, word_vec_dim = 100, input_file='/data/QA/QA_pair.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(object):\n",
    "    def __init__(self):\n",
    "        self.max_abs_weight = 32  # 最大权重绝对值，用来对词向量做正规化\n",
    "        self.max_seq_len = 1928  # 最大句子长度(词)\n",
    "        self.word_vec_dim = 100  # 词向量维度，读vectors.bin二进制时动态确定\n",
    "        self.epoch = 1000\n",
    "        self.word_vector_dict = {}  # 词向量词典，加载vectors.bin读入\n",
    "        self.one_hot_word_vector_dict = {}  # 根据样本词汇生成的softmax用的词向量\n",
    "        self.word_id_word_dict = {}\n",
    "        self.one_hot_word_vectors_dim = 1  # softmax用的词向量维度，从1开始，保留0作为EOS的word_id\n",
    "        self.eos_word_id = 0\n",
    "        self.eos_word = 'EOS'\n",
    "        self.vectors_bin_file = './vectors.bin'  # 词向量二进制\n",
    "        self.model_dir = './model/model'  # 模型文件路径\n",
    "        self.n_hidden = 1000  # lstm隐藏状态单元数目\n",
    "        self.learning_rate = 0.01  # 学习率\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
